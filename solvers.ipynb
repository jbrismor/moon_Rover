{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Solvers\"\n",
    "format:\n",
    "  html:\n",
    "    embed-resources: true\n",
    "    code-fold: true\n",
    "    toc: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "From the root directory, run \"pip install -e .\" in your current environment to download the package with the environment in order to wrap around gym and rllib. The information of the download is in setup.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versions and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.39.0\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "print(ray.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version     Editable project location\n",
      "------------------------- ----------- ---------------------------------\n",
      "absl-py                   2.1.0\n",
      "aiosignal                 1.3.2\n",
      "appnope                   0.1.4\n",
      "asttokens                 3.0.0\n",
      "attrs                     25.1.0\n",
      "certifi                   2025.1.31\n",
      "charset-normalizer        3.4.1\n",
      "click                     8.1.8\n",
      "cloudpickle               3.1.1\n",
      "cmake                     3.31.4\n",
      "comm                      0.2.2\n",
      "contourpy                 1.3.1\n",
      "cycler                    0.12.1\n",
      "debugpy                   1.8.12\n",
      "decorator                 5.1.1\n",
      "dm-tree                   0.1.9\n",
      "exceptiongroup            1.2.2\n",
      "executing                 2.1.0\n",
      "Farama-Notifications      0.0.4\n",
      "filelock                  3.17.0\n",
      "fonttools                 4.56.0\n",
      "frozenlist                1.5.0\n",
      "fsspec                    2025.2.0\n",
      "geosearch_package         0.1.0\n",
      "gymnasium                 1.0.0\n",
      "idna                      3.10\n",
      "importlib_metadata        8.6.1\n",
      "ipykernel                 6.29.5\n",
      "ipython                   8.32.0\n",
      "ipywidgets                8.1.5\n",
      "jedi                      0.19.2\n",
      "Jinja2                    3.1.5\n",
      "jsonschema                4.23.0\n",
      "jsonschema-specifications 2024.10.1\n",
      "jupyter_client            8.6.3\n",
      "jupyter_core              5.7.2\n",
      "jupyterlab_widgets        3.0.13\n",
      "kiwisolver                1.4.8\n",
      "lunabot                   1.1.0       /Users/jbm/Desktop/moon_Rover/src\n",
      "lz4                       4.4.3\n",
      "MarkupSafe                3.0.2\n",
      "matplotlib                3.10.0\n",
      "matplotlib-inline         0.1.7\n",
      "mpmath                    1.3.0\n",
      "msgpack                   1.1.0\n",
      "nest_asyncio              1.6.0\n",
      "networkx                  3.4.2\n",
      "noise                     1.2.2\n",
      "numpy                     1.26.4\n",
      "packaging                 24.2\n",
      "pandas                    2.2.3\n",
      "parso                     0.8.4\n",
      "pexpect                   4.9.0\n",
      "pickleshare               0.7.5\n",
      "pillow                    11.1.0\n",
      "pip                       25.0\n",
      "platformdirs              4.3.6\n",
      "prompt_toolkit            3.0.50\n",
      "protobuf                  5.29.3\n",
      "psutil                    6.1.1\n",
      "ptyprocess                0.7.0\n",
      "pure_eval                 0.2.3\n",
      "pyarrow                   17.0.0\n",
      "pygame                    2.6.1\n",
      "Pygments                  2.19.1\n",
      "pyparsing                 3.2.1\n",
      "python-dateutil           2.9.0.post0\n",
      "pytz                      2025.1\n",
      "PyYAML                    6.0.2\n",
      "pyzmq                     26.2.1\n",
      "ray                       2.39.0\n",
      "referencing               0.36.2\n",
      "requests                  2.32.3\n",
      "rpds-py                   0.22.3\n",
      "scipy                     1.14.1\n",
      "setuptools                75.8.0\n",
      "six                       1.17.0\n",
      "stack_data                0.6.3\n",
      "sympy                     1.13.3\n",
      "tensorboardX              2.6.2.2\n",
      "torch                     2.2.2\n",
      "tornado                   6.4.2\n",
      "tqdm                      4.67.1\n",
      "traitlets                 5.14.3\n",
      "typing_extensions         4.12.2\n",
      "tzdata                    2025.1\n",
      "urllib3                   2.3.0\n",
      "wcwidth                   0.2.13\n",
      "wheel                     0.45.1\n",
      "widgetsnbextension        4.0.13\n",
      "wrapt                     1.17.2\n",
      "zipp                      3.21.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Run the pip list command and print the output\n",
    "installed_packages = subprocess.run([\"pip\", \"list\"], capture_output=True, text=True)\n",
    "print(installed_packages.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from gymnasium.envs.registration import register\n",
    "import gymnasium as gym\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.algorithms.sac import SACConfig\n",
    "from ray.rllib.algorithms.dqn import DQNConfig\n",
    "import numpy as np\n",
    "from ray import tune\n",
    "from ray.rllib.algorithms.appo import APPOConfig\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pygame\n",
    "from ray.rllib.models.torch.torch_action_dist import TorchCategorical\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up matplotlib interactive mode\n",
    "is_ipython = 'inline' in plt.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lunabot.geosearch import GeosearchEnv, Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: {'water_prob': array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.1501686 , 0.22006331, 0.25027737,\n",
      "         0.221329  , 0.15302058, 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.150178  , 0.28381914, 0.41620472, 0.        ,\n",
      "         0.        , 0.        , 0.17151755, 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.22020513, 0.41633102, 0.6114779 , 0.        ,\n",
      "         0.        , 0.        , 0.29745248, 0.17968751, 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.2516258 , 0.47592708, 0.7010929 , 0.        ,\n",
      "         0.        , 0.        , 0.4610487 , 0.34607494, 0.24367195,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.22993356, 0.43381634, 0.6406358 , 0.7570687 ,\n",
      "         0.7555367 , 0.7007684 , 0.65298074, 0.5886554 , 0.4604317 ,\n",
      "         0.288078  , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.19114791, 0.35320735, 0.51327944, 0.6144906 ,\n",
      "         0.6668505 , 0.7334353 , 0.81918085, 0.8281656 , 0.6829683 ,\n",
      "         0.43652418, 0.21197662, 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.20370968, 0.35465074, 0.47855058, 0.5385895 ,\n",
      "         0.5868832 , 0.7037179 , 0.8627469 , 0.9197827 , 0.7762643 ,\n",
      "         0.5007229 , 0.24401781, 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.3078207 , 0.50947785, 0.6319236 , 0.6234361 ,\n",
      "         0.575819  , 0.6167172 , 0.73605627, 0.7880967 , 0.66902864,\n",
      "         0.43291438, 0.21126851, 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.20371445, 0.45426005, 0.73877543, 0.8830728 , 0.79935193,\n",
      "         0.60953295, 0.4999947 , 0.50716686, 0.51778203, 0.43567565,\n",
      "         0.28165415, 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.23504177, 0.5230732 , 0.8466862 , 1.        , 0.8731526 ,\n",
      "         0.59454787, 0.37618375, 0.29003042, 0.26270217, 0.21450792,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.19961375, 0.44400457, 0.71773034, 0.8442938 , 0.72688496,\n",
      "         0.46945626, 0.2507795 , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.2746131 , 0.44371435, 0.521184  , 0.44616115,\n",
      "         0.28152305, 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ]],\n",
      "\n",
      "       [[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 1.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.        ]]],\n",
      "      dtype=float32), 'battery': array([1.], dtype=float32), 'sunlight': array([0.], dtype=float32), 'dust': array([0.26947305], dtype=float32), 'local_heights': array([ 0.        , -0.09476782,  0.10941853,  0.06024754, -0.07910047],\n",
      "      dtype=float32), 'location_depleted': array([0.], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "register(\n",
    "    id=\"GeosearchEnv-v0\",\n",
    "    entry_point=\"geosearch_package.geosearch:GeosearchEnv\",\n",
    ")\n",
    "env = GeosearchEnv()\n",
    "#env = gym.make(\"GeosearchEnv-v0\")\n",
    "obs, info = env.reset()\n",
    "print(\"Observation:\", obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions to visualize training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(rewards, lengths):\n",
    "    fig = plt.figure(1, figsize=(16, 8))\n",
    "    plt.clf()\n",
    "\n",
    "    # plt.subplots(ncols=2, figsize=(12,6))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "    ax1.set_title('Mean Rewards')\n",
    "    ax1.set_xlabel('Evaluation Interval')\n",
    "    ax1.set_ylabel('Mean Reward')\n",
    "    ax1.plot(rewards)\n",
    "\n",
    "    ax2.set_title('Mean Episode Length')\n",
    "    ax2.set_xlabel('Evaluation Interval')\n",
    "    ax2.set_ylabel('Episode Length')\n",
    "    ax2.plot(lengths)\n",
    "    \n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a generic policy wrapper class that works with all RLlib algorithms\n",
    "class RLlibPolicyWrapper:\n",
    "    def __init__(self, algo):\n",
    "        self.algo = algo\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "    def process_state(self, state):\n",
    "        # Convert dictionary observation to array\n",
    "        state_array = np.concatenate([\n",
    "            state['height'],\n",
    "            state['battery'],\n",
    "            state['position'],\n",
    "            state['sunlight'],\n",
    "            state['dust'],\n",
    "            state['water_prob'],\n",
    "            state['gold_prob']\n",
    "        ])\n",
    "        return state_array\n",
    "        \n",
    "    def get_action(self, state):\n",
    "        # Get action from policy\n",
    "        action = self.algo.compute_single_action(\n",
    "            observation=state,\n",
    "            explore=False  # Don't use exploration during visualization\n",
    "        )\n",
    "        return action\n",
    "\n",
    "def visualize_policy(env, algo, algo_name=\"Algorithm\", episodes=5, max_steps=50, save_gif=True, gif_dir=\"policy_gifs\"):\n",
    "    \"\"\"\n",
    "    Generic function to visualize any RLlib algorithm's policy.\n",
    "    \n",
    "    Args:\n",
    "        env: The environment instance\n",
    "        algo: The RLlib algorithm instance (PPO, SAC, DQN, or APPO)\n",
    "        algo_name: Name of the algorithm for the output filename\n",
    "        episodes: Number of episodes to run\n",
    "        max_steps: Maximum steps per episode\n",
    "        save_gif: Whether to save the visualization as a GIF\n",
    "        gif_dir: Directory to save the GIFs (default: \"policy_gifs\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize Pygame first\n",
    "        pygame.init()\n",
    "        \n",
    "        # Create policy wrapper\n",
    "        policy_wrapper = RLlibPolicyWrapper(algo)\n",
    "        \n",
    "        # Initialize visualization\n",
    "        if env.render_mode != 'human':\n",
    "            env.render_mode = 'human'\n",
    "        env._init_render()\n",
    "        \n",
    "        frames = []\n",
    "        total_reward = 0\n",
    "        \n",
    "        # Create directory for GIFs if it doesn't exist\n",
    "        if save_gif:\n",
    "            os.makedirs(gif_dir, exist_ok=True)\n",
    "            gif_path = os.path.join(gif_dir, f\"{algo_name.lower()}_policy.gif\")\n",
    "            print(f\"GIF will be saved to: {gif_path}\")\n",
    "        \n",
    "        for episode in range(episodes):\n",
    "            state, info = env.reset()\n",
    "            episode_reward = 0\n",
    "            terminated = False\n",
    "            steps = 0\n",
    "            \n",
    "            while not terminated and steps < max_steps:\n",
    "                # Handle Pygame events\n",
    "                for event in pygame.event.get():\n",
    "                    if event.type == pygame.QUIT:\n",
    "                        raise KeyboardInterrupt\n",
    "                \n",
    "                # Render current state\n",
    "                env.render()\n",
    "                if save_gif:\n",
    "                    frame = pygame.surfarray.array3d(env.screen)\n",
    "                    frames.append(np.transpose(frame, (1, 0, 2)))\n",
    "                \n",
    "                # Get action from policy\n",
    "                action = policy_wrapper.get_action(state)\n",
    "                \n",
    "                # Take action in environment\n",
    "                next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "                \n",
    "                episode_reward += reward\n",
    "                state = next_state\n",
    "                steps += 1\n",
    "                \n",
    "                # Add small delay for visualization\n",
    "                pygame.time.wait(66)  # ~15 FPS\n",
    "                \n",
    "            total_reward += episode_reward\n",
    "            print(f\"Episode {episode + 1} finished with reward: {episode_reward:.2f}\")\n",
    "        \n",
    "        if save_gif and frames:\n",
    "            Utils.create_gif(frames, filename=gif_path, duration=66)\n",
    "            print(f\"GIF saved successfully to {gif_path}\")\n",
    "        \n",
    "        avg_reward = total_reward / episodes\n",
    "        print(f\"Average reward over {episodes} episodes: {avg_reward:.2f}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nVisualization interrupted by user\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during visualization: {str(e)}\")\n",
    "    \n",
    "    finally:\n",
    "        # Ensure proper cleanup\n",
    "        if hasattr(env, 'close'):\n",
    "            env.close()\n",
    "        \n",
    "        # Additional Pygame cleanup\n",
    "        pygame.quit()\n",
    "        print(\"Visualization completed and resources cleaned up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Enhanced Custom Model with Recommendations\n",
    "# ------------------------------------------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.models import ModelCatalog\n",
    "\n",
    "class AddCoordinates(nn.Module):\n",
    "    \"\"\"Add normalized coordinate channels to input grid\"\"\"\n",
    "    def __init__(self, grid_size=20):\n",
    "        super().__init__()\n",
    "        xx, yy = torch.meshgrid(\n",
    "            torch.linspace(-1, 1, grid_size),\n",
    "            torch.linspace(-1, 1, grid_size),\n",
    "            indexing='xy'  # Ensure consistent indexing\n",
    "        )\n",
    "        # Clone tensors to avoid shared memory\n",
    "        self.register_buffer('xx', xx.clone())\n",
    "        self.register_buffer('yy', yy.clone())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        coords = torch.stack([self.xx, self.yy], dim=0)\n",
    "        coords = coords.unsqueeze(0).expand(batch_size, -1, -1, -1)\n",
    "        return torch.cat([x, coords], dim=1)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    \"\"\"Attention over spatial features\"\"\"\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.query = nn.Conv2d(in_channels, in_channels//8, 1)\n",
    "        self.key = nn.Conv2d(in_channels, in_channels//8, 1)\n",
    "        self.value = nn.Conv2d(in_channels, in_channels, 1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, C, H, W = x.size()\n",
    "        query = self.query(x).view(batch_size, -1, H*W).permute(0, 2, 1)\n",
    "        key = self.key(x).view(batch_size, -1, H*W)\n",
    "        energy = torch.bmm(query, key)\n",
    "        attention = F.softmax(energy, dim=-1)\n",
    "        value = self.value(x).view(batch_size, -1, H*W)\n",
    "        out = torch.bmm(value, attention.permute(0, 2, 1))\n",
    "        out = out.view(batch_size, C, H, W)\n",
    "        return self.gamma*out + x\n",
    "\n",
    "class EnhancedGeosearchModel(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        self.grid_size = 20\n",
    "\n",
    "        # ========== Spatial Processing Branch ==========\n",
    "        self.coord_adder = AddCoordinates(self.grid_size)\n",
    "        self.conv_net = nn.Sequential(\n",
    "            nn.Conv2d(4, 32, 5, padding=2),  # 4 channels: water_prob + coords\n",
    "            nn.BatchNorm2d(32),\n",
    "            SpatialAttention(32),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            SpatialAttention(64),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            SpatialAttention(128),\n",
    "            \n",
    "            nn.AdaptiveAvgPool2d((4, 4))\n",
    "        )\n",
    "\n",
    "        # ========== Non-Spatial Processing Branch ==========\n",
    "        # Height processing\n",
    "        self.height_net = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(16, 32, 3),\n",
    "            nn.AdaptiveMaxPool1d(1),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        # Other features processing\n",
    "        self.feature_net = nn.Sequential(\n",
    "            nn.Linear(4, 64),  # battery, sunlight, dust, depleted\n",
    "            nn.LayerNorm(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # ========== Cross-Modal Fusion ==========\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(2048 + 32 + 64, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # ========== Output Heads ==========\n",
    "        self.policy_head = nn.Sequential(\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_outputs)\n",
    "        )\n",
    "        \n",
    "        self.value_head = nn.Sequential(\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "        \n",
    "        self.aux_head = nn.Linear(256, 1)\n",
    "\n",
    "        # ========== Normalization ==========\n",
    "        self.register_buffer('water_mean', torch.tensor([0.3, 0.0]))\n",
    "        self.register_buffer('water_std', torch.tensor([0.15, 1.0]))\n",
    "\n",
    "\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs = input_dict[\"obs\"]\n",
    "\n",
    "        # Check if the observation is a dict or a flattened tensor.\n",
    "        if isinstance(obs, dict):\n",
    "            # Expect keys: water_prob, battery, sunlight, dust, local_heights, location_depleted\n",
    "            water_prob = obs[\"water_prob\"]\n",
    "            battery = obs[\"battery\"]\n",
    "            sunlight = obs[\"sunlight\"]\n",
    "            dust = obs[\"dust\"]\n",
    "            local_heights = obs[\"local_heights\"]\n",
    "            location_depleted = obs[\"location_depleted\"]\n",
    "            # Ensure water_prob is 4D: [B, 2, 20, 20]\n",
    "            water_prob = water_prob.view(-1, 2, 20, 20)\n",
    "        else:\n",
    "            # Otherwise, assume a flat observation of length 809:\n",
    "            # 800 for water_prob (2*20*20), then battery (1), sunlight (1),\n",
    "            # dust (1), local_heights (5), location_depleted (1)\n",
    "            water_prob = obs[:, :800].view(-1, 2, 20, 20)\n",
    "            battery = obs[:, 800:801]\n",
    "            sunlight = obs[:, 801:802]\n",
    "            dust = obs[:, 802:803]\n",
    "            local_heights = obs[:, 803:808]\n",
    "            location_depleted = obs[:, 808:809]\n",
    "\n",
    "        # ========== Input Normalization ==========\n",
    "        # Reshape water_mean and water_std to broadcast properly.\n",
    "        water_map = (water_prob - self.water_mean.view(1, 2, 1, 1)) / self.water_std.view(1, 2, 1, 1)\n",
    "\n",
    "        # Process non-spatial features ensuring they are 2D (batch_size, feature_dim)\n",
    "        non_spatial = torch.cat([\n",
    "            battery.view(-1, 1),\n",
    "            sunlight.view(-1, 1),\n",
    "            dust.view(-1, 1),\n",
    "            location_depleted.view(-1, 1)\n",
    "        ], dim=-1)\n",
    "\n",
    "        # ========== Spatial Processing ==========\n",
    "        spatial_feat = self.coord_adder(water_map)\n",
    "        spatial_feat = self.conv_net(spatial_feat)\n",
    "        spatial_feat = spatial_feat.flatten(start_dim=1)  # Shape: [B, features]\n",
    "\n",
    "        # ========== Non-Spatial Processing ==========\n",
    "        # Process local heights: reshape to [B, 1, 5] for Conv1d\n",
    "        heights = local_heights.unsqueeze(1)\n",
    "        height_feat = self.height_net(heights)       # Shape: [B, 32]\n",
    "        feature_feat = self.feature_net(non_spatial)   # Shape: [B, 64]\n",
    "\n",
    "        # ========== Fusion ==========\n",
    "        fused = torch.cat([spatial_feat, height_feat, feature_feat], dim=-1)\n",
    "        fused = self.fusion(fused)\n",
    "\n",
    "        # ========== Outputs ==========\n",
    "        logits = self.policy_head(fused)\n",
    "        self._value_out = self.value_head(fused)\n",
    "\n",
    "        return logits, state\n",
    "\n",
    "    def value_function(self):\n",
    "        return self._value_out.squeeze(-1)\n",
    "\n",
    "    def forward_train(self, input_dict, state, seq_lens):\n",
    "        logits, state_out = self.forward(input_dict, state, seq_lens)\n",
    "        \n",
    "        # Auxiliary task: Water presence prediction\n",
    "        if \"water_label\" in input_dict:\n",
    "            aux_out = self.aux_head(self.fusion_out)\n",
    "            aux_loss = F.binary_cross_entropy_with_logits(\n",
    "                aux_out, input_dict[\"water_label\"].float())\n",
    "            self._aux_loss = aux_loss\n",
    "        else:\n",
    "            self._aux_loss = 0.0\n",
    "            \n",
    "        return logits, state_out\n",
    "\n",
    "    def loss(self, model_out, dist_class, train_batch):\n",
    "        base_loss = super().loss(model_out, dist_class, train_batch)\n",
    "        return base_loss + 0.2 * self._aux_loss\n",
    "\n",
    "# Register the model\n",
    "ModelCatalog.register_custom_model(\"geo_model\", EnhancedGeosearchModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-14 16:35:59,004\tWARNING deprecation.py:50 -- DeprecationWarning: `AlgorithmConfig.evaluation_num_workers` has been deprecated. Use `AlgorithmConfig.evaluation_num_env_runners` instead. This will raise an error in the future!\n",
      "/Users/jbm/miniforge3/envs/rover/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:567: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/Users/jbm/miniforge3/envs/rover/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/Users/jbm/miniforge3/envs/rover/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/Users/jbm/miniforge3/envs/rover/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2025-02-14 16:36:00,317\tINFO worker.py:1819 -- Started a local Ray instance.\n",
      "2025-02-14 16:36:03,784\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RolloutWorker pid=83731)\u001b[0m [W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.sac import SACConfig\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------\n",
    "# SAC Configuration and Algorithm Build\n",
    "# ------------------------------------------\n",
    "from ray.rllib.algorithms.sac import SACConfig\n",
    "\n",
    "config = SACConfig()\n",
    "config.framework_str = \"torch\"\n",
    "config.env = GeosearchEnv\n",
    "\n",
    "# IMPORTANT: Disable RLlib's preprocessor so that dict observations are preserved.\n",
    "config.model = {\n",
    "    \"_disable_preprocessor_api\": True,\n",
    "    \"max_seq_len\": 20\n",
    "}\n",
    "\n",
    "\n",
    "config.training(\n",
    "    policy_model_config={\n",
    "        \"custom_model\": \"geo_model\",\n",
    "        \"custom_action_dist\": \"categorical\",\n",
    "    },\n",
    "    q_model_config={\n",
    "        \"custom_model\": \"geo_model\",\n",
    "        \"custom_action_dist\": \"categorical\",\n",
    "    },\n",
    "    lr=3e-4,\n",
    "    tau=0.005,\n",
    "    initial_alpha=0.2,\n",
    "    target_entropy=\"auto\",\n",
    "    train_batch_size=512,\n",
    "    replay_buffer_config={\n",
    "        \"type\": \"ReplayBuffer\",\n",
    "        \"capacity\": 500000,\n",
    "        \"alpha\": 0.6,\n",
    "        \"beta\": 0.4\n",
    "    }\n",
    ")\n",
    "\n",
    "config.rollout_fragment_length = 200\n",
    "config.num_workers = 8\n",
    "config.evaluation_num_workers = 4\n",
    "config.evaluation_interval = 50\n",
    "config.evaluation_duration = 30\n",
    "\n",
    "# config.gamma = 0.99\n",
    "# config.exploration_config = {\n",
    "#     \"type\": \"EpsilonGreedy\",\n",
    "#     \"initial_epsilon\": 1.0,\n",
    "#     \"final_epsilon\": 0.05,\n",
    "#     \"epsilon_timesteps\": 300000,\n",
    "# }\n",
    "\n",
    "config.api_stack(\n",
    "    enable_rl_module_and_learner=False,\n",
    "    enable_env_runner_and_connector_v2=False\n",
    ")\n",
    "\n",
    "algo = config.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "lengths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(TRAINING_ITERATIONS):\n\u001b[0;32m---> 12\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m EVAL_INTERVAL \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     15\u001b[0m         evaluation_results \u001b[38;5;241m=\u001b[39m algo\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m~/miniforge3/envs/rover/lib/python3.10/site-packages/ray/tune/trainable/trainable.py:328\u001b[0m, in \u001b[0;36mTrainable.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    326\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 328\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    330\u001b[0m     skipped \u001b[38;5;241m=\u001b[39m skip_exceptions(e)\n",
      "File \u001b[0;32m~/miniforge3/envs/rover/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:933\u001b[0m, in \u001b[0;36mAlgorithm.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    923\u001b[0m     (\n\u001b[1;32m    924\u001b[0m         train_results,\n\u001b[1;32m    925\u001b[0m         eval_results,\n\u001b[1;32m    926\u001b[0m         train_iter_ctx,\n\u001b[1;32m    927\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_one_training_iteration_and_evaluation_in_parallel()\n\u001b[1;32m    929\u001b[0m \u001b[38;5;66;03m# - No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# - We have to evaluate in this training iteration, but no parallelism ->\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \u001b[38;5;66;03m#   evaluate after the training iteration is entirely done.\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 933\u001b[0m     train_results, train_iter_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_one_training_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;66;03m# Sequential: Train (already done above), then evaluate.\u001b[39;00m\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluate_this_iter \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mevaluation_parallel_to_training:\n",
      "File \u001b[0;32m~/miniforge3/envs/rover/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:3498\u001b[0m, in \u001b[0;36mAlgorithm._run_one_training_iteration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3494\u001b[0m \u001b[38;5;66;03m# Try to train one step.\u001b[39;00m\n\u001b[1;32m   3495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timers[TRAINING_STEP_TIMER]:\n\u001b[1;32m   3496\u001b[0m     \u001b[38;5;66;03m# TODO (sven): Should we reduce the different\u001b[39;00m\n\u001b[1;32m   3497\u001b[0m     \u001b[38;5;66;03m#  `training_step_results` over time with MetricsLogger.\u001b[39;00m\n\u001b[0;32m-> 3498\u001b[0m     training_step_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training_step_results:\n\u001b[1;32m   3501\u001b[0m     results \u001b[38;5;241m=\u001b[39m training_step_results\n",
      "File \u001b[0;32m~/miniforge3/envs/rover/lib/python3.10/site-packages/ray/rllib/algorithms/sac/sac.py:615\u001b[0m, in \u001b[0;36mSAC.training_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_training_step_new_api_stack(with_noise_reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    612\u001b[0m \u001b[38;5;66;03m# Old API stack (Policy, RolloutWorker, Connector, maybe RLModule,\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;66;03m# maybe Learner).\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 615\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_training_step_old_api_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/rover/lib/python3.10/site-packages/ray/rllib/algorithms/dqn/dqn.py:886\u001b[0m, in \u001b[0;36mDQN._training_step_old_api_stack\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    884\u001b[0m     train_results \u001b[38;5;241m=\u001b[39m train_one_step(\u001b[38;5;28mself\u001b[39m, train_batch)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 886\u001b[0m     train_results \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_gpu_train_one_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;66;03m# Update replay buffer priorities.\u001b[39;00m\n\u001b[1;32m    889\u001b[0m update_priorities_in_replay_buffer(\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_replay_buffer,\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m    892\u001b[0m     train_batch,\n\u001b[1;32m    893\u001b[0m     train_results,\n\u001b[1;32m    894\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/rover/lib/python3.10/site-packages/ray/rllib/execution/train_ops.py:180\u001b[0m, in \u001b[0;36mmulti_gpu_train_one_step\u001b[0;34m(algorithm, train_batch)\u001b[0m\n\u001b[1;32m    175\u001b[0m         permutation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(num_batches)\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m batch_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m    177\u001b[0m             \u001b[38;5;66;03m# Learn on the pre-loaded data in the buffer.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m             \u001b[38;5;66;03m# Note: For minibatch SGD, the data is an offset into\u001b[39;00m\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;66;03m# the pre-loaded entire train batch.\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m             results \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn_on_loaded_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpermutation\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mper_device_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m    182\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m             learner_info_builder\u001b[38;5;241m.\u001b[39madd_learn_on_batch_results(results, policy_id)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# Tower reduce and finalize results.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/rover/lib/python3.10/site-packages/ray/rllib/policy/torch_policy.py:568\u001b[0m, in \u001b[0;36mTorchPolicy.learn_on_loaded_batch\u001b[0;34m(self, offset, buffer_index)\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    567\u001b[0m         batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loaded_batches[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][offset : offset \u001b[38;5;241m+\u001b[39m device_batch_size]\n\u001b[0;32m--> 568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevices) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# Copy weights of main model (tower-0) to all other towers.\u001b[39;00m\n\u001b[1;32m    572\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstate_dict()\n",
      "File \u001b[0;32m~/miniforge3/envs/rover/lib/python3.10/site-packages/ray/rllib/utils/threading.py:24\u001b[0m, in \u001b[0;36mwith_lock.<locals>.wrapper\u001b[0;34m(self, *a, **k)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 24\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_lock\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/miniforge3/envs/rover/lib/python3.10/site-packages/ray/rllib/policy/torch_policy.py:455\u001b[0m, in \u001b[0;36mTorchPolicy.learn_on_batch\u001b[0;34m(self, postprocessed_batch)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mon_learn_on_batch(\n\u001b[1;32m    450\u001b[0m     policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, train_batch\u001b[38;5;241m=\u001b[39mpostprocessed_batch, result\u001b[38;5;241m=\u001b[39mlearn_stats\n\u001b[1;32m    451\u001b[0m )\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# Compute gradients (will calculate all losses and `backward()`\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# them to get the grads).\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m grads, fetches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpostprocessed_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;66;03m# Step the optimizers.\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_gradients(_directStepOptimizerSingleton)\n",
      "File \u001b[0;32m~/miniforge3/envs/rover/lib/python3.10/site-packages/ray/rllib/policy/policy_template.py:377\u001b[0m, in \u001b[0;36mbuild_policy_class.<locals>.policy_cls.compute_gradients\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m compute_gradients_fn(\u001b[38;5;28mself\u001b[39m, batch)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparent_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/rover/lib/python3.10/site-packages/ray/rllib/utils/threading.py:24\u001b[0m, in \u001b[0;36mwith_lock.<locals>.wrapper\u001b[0;34m(self, *a, **k)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 24\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_lock\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/miniforge3/envs/rover/lib/python3.10/site-packages/ray/rllib/policy/torch_policy.py:654\u001b[0m, in \u001b[0;36mTorchPolicy.compute_gradients\u001b[0;34m(self, postprocessed_batch)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_tensor_dict(postprocessed_batch, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevices[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    653\u001b[0m \u001b[38;5;66;03m# Do the (maybe parallelized) gradient calculation step.\u001b[39;00m\n\u001b[0;32m--> 654\u001b[0m tower_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_multi_gpu_parallel_grad_calc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpostprocessed_batch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m all_grads, grad_info \u001b[38;5;241m=\u001b[39m tower_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    658\u001b[0m grad_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallreduce_latency\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizers)\n",
      "File \u001b[0;32m~/miniforge3/envs/rover/lib/python3.10/site-packages/ray/rllib/policy/torch_policy.py:1150\u001b[0m, in \u001b[0;36mTorchPolicy._multi_gpu_parallel_grad_calc\u001b[0;34m(self, sample_batches)\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevices) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_fake_gpus\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m shard_idx, (model, sample_batch, device) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_gpu_towers, sample_batches, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevices)\n\u001b[1;32m   1149\u001b[0m     ):\n\u001b[0;32m-> 1150\u001b[0m         \u001b[43m_worker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1151\u001b[0m         \u001b[38;5;66;03m# Raise errors right away for better debugging.\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m         last_result \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;28mlen\u001b[39m(results) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/rover/lib/python3.10/site-packages/ray/rllib/policy/torch_policy.py:1069\u001b[0m, in \u001b[0;36mTorchPolicy._multi_gpu_parallel_grad_calc.<locals>._worker\u001b[0;34m(shard_idx, model, sample_batch, device)\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m NullContextManager() \u001b[38;5;28;01mif\u001b[39;00m device\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m         device\n\u001b[1;32m   1067\u001b[0m     ):\n\u001b[1;32m   1068\u001b[0m         loss_out \u001b[38;5;241m=\u001b[39m force_list(\n\u001b[0;32m-> 1069\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdist_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1070\u001b[0m         )\n\u001b[1;32m   1072\u001b[0m         \u001b[38;5;66;03m# Call Model's custom-loss with Policy loss outputs and\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;66;03m# train_batch.\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m         loss_out \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcustom_loss(loss_out, sample_batch)\n",
      "File \u001b[0;32m~/miniforge3/envs/rover/lib/python3.10/site-packages/ray/rllib/algorithms/sac/sac_torch_policy.py:224\u001b[0m, in \u001b[0;36mactor_critic_loss\u001b[0;34m(policy, model, dist_class, train_batch)\u001b[0m\n\u001b[1;32m    222\u001b[0m q_tp1, _ \u001b[38;5;241m=\u001b[39m target_model\u001b[38;5;241m.\u001b[39mget_q_values(target_model_out_tp1)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m policy\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwin_q\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 224\u001b[0m     twin_q_t, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_twin_q_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_out_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m     twin_q_tp1, _ \u001b[38;5;241m=\u001b[39m target_model\u001b[38;5;241m.\u001b[39mget_twin_q_values(target_model_out_tp1)\n\u001b[1;32m    226\u001b[0m     q_tp1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmin(q_tp1, twin_q_tp1)\n",
      "File \u001b[0;32m~/miniforge3/envs/rover/lib/python3.10/site-packages/ray/rllib/algorithms/sac/sac_torch_model.py:239\u001b[0m, in \u001b[0;36mSACTorchModel.get_twin_q_values\u001b[0;34m(self, model_out, actions)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_twin_q_values\u001b[39m(\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m, model_out: TensorType, actions: Optional[TensorType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    224\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TensorType:\n\u001b[1;32m    225\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Same as get_q_values but using the twin Q net.\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m    This implements the twin Q(s, a).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m        TensorType: Q-values tensor of shape [BATCH_SIZE, 1].\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_q_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtwin_q_net\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/rover/lib/python3.10/site-packages/ray/rllib/algorithms/sac/sac_torch_model.py:265\u001b[0m, in \u001b[0;36mSACTorchModel._get_q_value\u001b[0;34m(self, model_out, actions, net)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Switch on training mode (when getting Q-values, we are usually in\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# training).\u001b[39;00m\n\u001b[1;32m    263\u001b[0m input_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_training\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/rover/lib/python3.10/site-packages/ray/rllib/models/modelv2.py:256\u001b[0m, in \u001b[0;36mModelV2.__call__\u001b[0;34m(self, input_dict, state, seq_lens)\u001b[0m\n\u001b[1;32m    253\u001b[0m         restored[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs_flat\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m input_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext():\n\u001b[0;32m--> 256\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrestored\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_lens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(input_dict, SampleBatch):\n\u001b[1;32m    259\u001b[0m     input_dict\u001b[38;5;241m.\u001b[39maccessed_keys \u001b[38;5;241m=\u001b[39m restored\u001b[38;5;241m.\u001b[39maccessed_keys \u001b[38;5;241m-\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs_flat\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "Cell \u001b[0;32mIn[9], line 160\u001b[0m, in \u001b[0;36mEnhancedGeosearchModel.forward\u001b[0;34m(self, input_dict, state, seq_lens)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# ========== Spatial Processing ==========\u001b[39;00m\n\u001b[1;32m    159\u001b[0m spatial_feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoord_adder(water_map)\n\u001b[0;32m--> 160\u001b[0m spatial_feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspatial_feat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m spatial_feat \u001b[38;5;241m=\u001b[39m spatial_feat\u001b[38;5;241m.\u001b[39mflatten(start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Shape: [B, features]\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# ========== Non-Spatial Processing ==========\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# Process local heights: reshape to [B, 1, 5] for Conv1d\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/rover/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/rover/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/rover/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/rover/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/rover/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 43\u001b[0m, in \u001b[0;36mSpatialAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey(x)\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, H\u001b[38;5;241m*\u001b[39mW)\n\u001b[1;32m     42\u001b[0m energy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(query, key)\n\u001b[0;32m---> 43\u001b[0m attention \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43menergy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue(x)\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, H\u001b[38;5;241m*\u001b[39mW)\n\u001b[1;32m     45\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(value, attention\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/miniforge3/envs/rover/lib/python3.10/site-packages/torch/nn/functional.py:1858\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1856\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1858\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1860\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "TRAINING_ITERATIONS = 9000\n",
    "EVAL_INTERVAL = 50\n",
    "\n",
    "\n",
    "# Modified training loop with better tracking\n",
    "best_reward = float('-inf')\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(TRAINING_ITERATIONS):\n",
    "    result = algo.train()\n",
    "    \n",
    "    if (i+1) % EVAL_INTERVAL == 0:\n",
    "        evaluation_results = algo.evaluate()\n",
    "        current_reward = evaluation_results['env_runners']['episode_return_mean']\n",
    "        rewards.append(current_reward)\n",
    "        lengths.append(evaluation_results['env_runners']['episode_len_mean'])\n",
    "        \n",
    "        # Save best model\n",
    "        if current_reward > best_reward:\n",
    "            best_reward = current_reward\n",
    "            checkpoint_dir_sac = f\"checkpoints/sac_best_reward\"\n",
    "            algo.save(checkpoint_dir_sac)\n",
    "            \n",
    "        # Print progress\n",
    "        elapsed_time = (time.time() - start_time) / 3600  # in hours\n",
    "        print(f\"\\nIteration {i+1}/{TRAINING_ITERATIONS}\")\n",
    "        print(f\"Time elapsed: {elapsed_time:.2f} hours\")\n",
    "        print(f\"Current reward: {current_reward:.2f}\")\n",
    "        print(f\"Best reward so far: {best_reward:.2f}\")\n",
    "        \n",
    "        plot_metrics(rewards, lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#policy = algo.get_policy()\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# weights = algo.get_weights()\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18;43m__file__\u001b[39;49m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "#policy = algo.get_policy()\n",
    "# weights = algo.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize how the algorithm performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'algo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# For SAC\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# For SAC: Ensure you load the best model\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43malgo\u001b[49m\u001b[38;5;241m.\u001b[39mrestore(checkpoint_dir_sac)\n\u001b[1;32m      5\u001b[0m env \u001b[38;5;241m=\u001b[39m GeosearchEnv(render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m visualize_policy(env, algo, algo_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msac_last\u001b[39m\u001b[38;5;124m\"\u001b[39m, episodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, max_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m365\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'algo' is not defined"
     ]
    }
   ],
   "source": [
    "# For SAC\n",
    "# For SAC: Ensure you load the best model\n",
    "algo.restore(checkpoint_dir_sac)\n",
    "\n",
    "env = GeosearchEnv(render_mode='human')\n",
    "visualize_policy(env, algo, algo_name=\"sac_last\", episodes=3, max_steps=365)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rover",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
